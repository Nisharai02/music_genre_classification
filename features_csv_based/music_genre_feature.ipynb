{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
      "0  blues.00000.wav  661794          0.350088         0.088757  0.130228   \n",
      "1  blues.00001.wav  661794          0.340914         0.094980  0.095948   \n",
      "2  blues.00002.wav  661794          0.363637         0.085275  0.175570   \n",
      "3  blues.00003.wav  661794          0.404785         0.093999  0.141093   \n",
      "4  blues.00004.wav  661794          0.308526         0.087841  0.091529   \n",
      "\n",
      "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
      "0  0.002827             1784.165850          129774.064525   \n",
      "1  0.002373             1530.176679          375850.073649   \n",
      "2  0.002746             1552.811865          156467.643368   \n",
      "3  0.006346             1070.106615          184355.942417   \n",
      "4  0.002303             1835.004266          343399.939274   \n",
      "\n",
      "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
      "0              2002.449060            85882.761315  ...   52.420910   \n",
      "1              2039.036516           213843.755497  ...   55.356403   \n",
      "2              1747.702312            76254.192257  ...   40.598766   \n",
      "3              1596.412872           166441.494769  ...   44.427753   \n",
      "4              1748.172116            88445.209036  ...   86.099236   \n",
      "\n",
      "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
      "0    -1.690215   36.524071    -0.408979   41.597103    -2.303523   55.062923   \n",
      "1    -0.731125   60.314529     0.295073   48.120598    -0.283518   51.106190   \n",
      "2    -7.729093   47.639427    -1.816407   52.382141    -3.439720   46.639660   \n",
      "3    -3.319597   50.206673     0.636965   37.319130    -0.619121   37.259739   \n",
      "4    -5.454034   75.269707    -0.916874   53.613918    -4.404827   62.910812   \n",
      "\n",
      "   mfcc20_mean  mfcc20_var  label  \n",
      "0     1.221291   46.936035  blues  \n",
      "1     0.531217   45.786282  blues  \n",
      "2    -2.231258   30.573025  blues  \n",
      "3    -3.407448   31.949339  blues  \n",
      "4   -11.703234   55.195160  blues  \n",
      "\n",
      "[5 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "features_data = pd.read_csv('features_30_sec.csv')\n",
    "print(features_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "blues        100\n",
      "classical    100\n",
      "country      100\n",
      "disco        100\n",
      "hiphop       100\n",
      "jazz         100\n",
      "metal        100\n",
      "pop          100\n",
      "reggae       100\n",
      "rock         100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count of each genre in the dataset\n",
    "print(features_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the labels into integers using label encoder\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "features_data['label'] = label_encoder.fit_transform(features_data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "class KNN_classifier():\n",
    "  def __init__(self,k):\n",
    "    self.k = k\n",
    "  \n",
    "  def fit(self,x_train,y_train):\n",
    "    self.x_train = x_train\n",
    "    self.y_train = y_train\n",
    "    self.r_train,self.c_train = x_train.shape\n",
    "\n",
    "  def euclidean_distance(self,x,y):\n",
    "    d = np.sqrt(np.sum(np.square(x-y)))\n",
    "    return d\n",
    "  \n",
    "  def predict(self,x_test):\n",
    "    self.x_test = x_test\n",
    "    self.r_test,self.c_test = x_test.shape\n",
    "    predictions = np.zeros(self.r_test)\n",
    "    for i in range(self.r_test):\n",
    "      x = self.x_test[i]\n",
    "      neighbors = np.zeros(self.k)\n",
    "      neighbors = self.k_nearest_neighbours(x)\n",
    "      predictions[i] = mode(neighbors, keepdims=True)[0][0]\n",
    "    return predictions\n",
    "\n",
    "  def k_nearest_neighbours(self,x):\n",
    "    distances = np.zeros(self.r_train)\n",
    "    for i in range(self.r_train):\n",
    "      d = self.euclidean_distance(x,self.x_train[i])\n",
    "      distances[i] = d\n",
    "    indices = distances.argsort()\n",
    "    y_train_res = self.y_train[indices]\n",
    "    return y_train_res[:self.k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the filename column since it is not relevant and also dropping label for splitting\n",
    "x = features_data.drop(['filename','label'],axis=1)\n",
    "y = features_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the data using MinMax Scaling\n",
    "# instantiating the minmax scaler\n",
    "cols = x.columns\n",
    "minmaxscaler = preprocessing.MinMaxScaler()\n",
    "scaled_values = minmaxscaler.fit_transform(x)\n",
    "# creating new data frame with the scaled values\n",
    "nf = pd.DataFrame(scaled_values, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x = nf.values\n",
    "y = y.values\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size = 0.3,random_state = 33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 64.33333333333333\n"
     ]
    }
   ],
   "source": [
    "model = KNN_classifier(k=5)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_predictions = model.predict(X_test)\n",
    "cnt = 0\n",
    "for i in range(len(Y_predictions)):\n",
    "  if Y_test[i] == Y_predictions[i]:\n",
    "    cnt+=1\n",
    "print(f\"Accuracy is {cnt/len(Y_test)*100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
